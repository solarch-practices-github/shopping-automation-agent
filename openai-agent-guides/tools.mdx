---
title: Tools
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../examples/docs/tools/mcpLocalServer.ts?raw';
import codexToolExample from '../../../../../examples/docs/tools/codexTool.ts?raw';

Tools let an Agent **take actions** – fetch data, call external APIs, execute code, or even use a
computer. The JavaScript/TypeScript SDK supports six categories:

1. **Hosted OpenAI tools** – run alongside the model on OpenAI servers. _(web search, file search, code interpreter, image generation)_
2. **Local built-in tools** – run in your environment. _(computer use, shell, apply_patch)_
3. **Function tools** – wrap any local function with a JSON schema so the LLM can call it.
4. **Agents as tools** – expose an entire Agent as a callable tool.
5. **MCP servers** – attach a Model Context Protocol server (local or remote).
6. **Experimental: Codex tool** – wrap the Codex SDK as a function tool to run workspace-aware tasks.

---

## 1. Hosted tools (OpenAI Responses API)

When you use the `OpenAIResponsesModel` you can add the following built‑in tools:

| Tool                    | Type string          | Purpose                               |
| ----------------------- | -------------------- | ------------------------------------- |
| Web search              | `'web_search'`       | Internet search.                      |
| File / retrieval search | `'file_search'`      | Query vector stores hosted on OpenAI. |
| Code Interpreter        | `'code_interpreter'` | Run code in a sandboxed environment.  |
| Image generation        | `'image_generation'` | Generate images based on text.        |

<Code lang="typescript" code={toolsHostedToolsExample} title="Hosted tools" />

The exact parameter sets match the OpenAI Responses API – refer to the official documentation
for advanced options like `rankingOptions` or semantic filters.

---

## 2. Local built-in tools

Local built-in tools run in your own environment and require you to supply implementations:

- **Computer use** – implement the `Computer` interface and pass it to `computerTool()`.
- **Shell** – implement the `Shell` interface and pass it to `shellTool()`.
- **Apply patch** – implement the `Editor` interface and pass it to `applyPatchTool()`.

These tools execute locally and are **not** hosted by OpenAI. Use them when you need direct access
to files, terminals, or GUI automation in your runtime. The tool calls are still requested by the
OpenAI model’s responses, but your application is expected to execute them locally.

<Code
  lang="typescript"
  code={localBuiltInToolsExample}
  title="Local built-in tools"
/>

---

## 3. Function tools

You can turn **any** function into a tool with the `tool()` helper.

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="Function tool with Zod parameters"
/>

### Options reference

| Field              | Required | Description                                                                                                                                                                       |
| ------------------ | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`             | No       | Defaults to the function name (e.g., `get_weather`).                                                                                                                              |
| `description`      | Yes      | Clear, human-readable description shown to the LLM.                                                                                                                               |
| `parameters`       | Yes      | Either a Zod schema or a raw JSON schema object. Zod parameters automatically enable **strict** mode.                                                                             |
| `strict`           | No       | When `true` (default), the SDK returns a model error if the arguments don't validate. Set to `false` for fuzzy matching.                                                          |
| `execute`          | Yes      | `(args, context) => string \| unknown \| Promise<...>` – your business logic. Non-string outputs are serialized for the model. The optional second parameter is the `RunContext`. |
| `errorFunction`    | No       | Custom handler `(context, error) => string` for transforming internal errors into a user-visible string.                                                                          |
| `needsApproval`    | No       | Require human approval before execution. See the [human-in-the-loop guide](/openai-agents-js/guides/human-in-the-loop).                                                           |
| `isEnabled`        | No       | Conditionally expose the tool per run; accepts a boolean or predicate.                                                                                                            |
| `inputGuardrails`  | No       | Guardrails that run before the tool executes; can reject or throw. See [Guardrails](/openai-agents-js/guides/guardrails#tool-guardrails).                                         |
| `outputGuardrails` | No       | Guardrails that run after the tool executes; can reject or throw. See [Guardrails](/openai-agents-js/guides/guardrails#tool-guardrails).                                          |

### Non‑strict JSON‑schema tools

If you need the model to _guess_ invalid or partial input you can disable strict mode when using
raw JSON schema:

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="Non-strict JSON schema tools"
/>

---

## 4. Agents as tools

Sometimes you want an Agent to _assist_ another Agent without fully handing off the conversation. Use `agent.asTool()`:

<Code lang="typescript" code={agentsAsToolsExample} title="Agents as tools" />

Under the hood the SDK:

- Creates a function tool with a single `input` parameter.
- Runs the sub‑agent with that input when the tool is called.
- Returns either the last message or the output extracted by `customOutputExtractor`.

When you run an agent as a tool, Agents SDK creates a runner with the default settings and run the agent with it within the function execution. If you want to provide any properties of `runConfig` or `runOptions`, you can pass them to the `asTool()` method to customize the runner's behavior.

You can also set `needsApproval` and `isEnabled` on the agent tool via `asTool()` options to integrate with human‑in‑the‑loop flows and conditional tool availability.

Advanced structured-input options for `agent.asTool()`:

- `inputBuilder`: maps structured tool args to the nested agent input payload.
- `includeInputSchema`: includes the input JSON schema in the nested run for stronger schema-aware behavior.
- `resumeState`: controls context reconciliation strategy when resuming nested serialized `RunState`.

### Streaming events from agent tools

Agent tools can stream all nested run events back to your app. Choose the hook style that fits how you construct the tool:

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="Streaming agent tools"
/>

- Event types match `RunStreamEvent['type']`: `raw_model_stream_event`, `run_item_stream_event`, `agent_updated_stream_event`.
- `onStream` is the simplest “catch-all” and works well when you declare the tool inline (`tools: [agent.asTool({ onStream })]`). Use it if you do not need per-event routing.
- `on(eventName, handler)` lets you subscribe selectively (or with `'*'`) and is best when you need finer-grained handling or want to attach listeners after creation.
- If you provide either `onStream` or any `on(...)` handler, the agent-as-tool will run in streaming mode automatically; without them it stays on the non-streaming path.
- Handlers are invoked in parallel so a slow `onStream` callback will not block `on(...)` handlers (and vice versa).
- `toolCallId` is provided when the tool was invoked via a model tool call; direct `invoke()` calls or provider quirks may omit it.

---

## 5. MCP servers

You can expose tools via [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) servers and attach them to an agent.
For instance, you can use `MCPServerStdio` to spawn and connect to the stdio MCP server:

<Code lang="typescript" code={mcpLocalServer} title="Local MCP server" />

See [`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts) for a complete example. Also, if you're looking for a comprehensitve guide for MCP server tool integration, refer to [MCP guide](/openai-agents-js/guides/mcp) for details.
When managing multiple servers (or partial failures), use `connectMcpServers` and the lifecycle guidance in the [MCP guide](/openai-agents-js/guides/mcp#managing-mcp-server-lifecycle).

---

## 6. Experimental: Codex tool

`@openai/agents-extensions/experimental/codex` provides `codexTool()`, a function tool that routes model tool calls to the Codex SDK so the agent can run workspace-scoped tasks (shell, file edits, MCP tools) autonomously. This surface is experimental and may change.

Quick start:

<Code
  lang="typescript"
  code={codexToolExample}
  title="Experimental Codex tool"
/>

What to know:

- Auth: supply `CODEX_API_KEY` (preferred) or `OPENAI_API_KEY`, or pass `codexOptions.apiKey`.
- Inputs: strict schema—`inputs` must contain at least one `{ type: 'text', text }` or `{ type: 'local_image', path }`.
- Safety: pair `sandboxMode` with `workingDirectory`; set `skipGitRepoCheck` if the directory is not a Git repo.
- Behavior: `persistSession: true` reuses a single Codex thread and returns its `threadId`; you can surface it for resumable work.
- Streaming: `onStream` mirrors Codex events (reasoning, command execution, MCP tool calls, file changes, web search) so you can log or trace progress.
- Outputs: tool result includes `response`, `usage`, and `threadId`, and Codex token usage is recorded in `RunContext`.
- Structure: `outputSchema` enforces structured Codex responses per turn when you need typed outputs.

---

## Tool use behavior

Refer to the [Agents guide](/openai-agents-js/guides/agents#forcing-tool-use) for controlling when and how a model
must use tools (`modelSettings.toolChoice`, `toolUseBehavior`, etc.).

---

## Best practices

- **Short, explicit descriptions** – describe _what_ the tool does _and when to use it_.
- **Validate inputs** – use Zod schemas for strict JSON validation where possible.
- **Avoid side‑effects in error handlers** – `errorFunction` should return a helpful string, not throw.
- **One responsibility per tool** – small, composable tools lead to better model reasoning.

---

## Next steps

- Learn about [forcing tool use](/openai-agents-js/guides/agents#forcing-tool-use).
- Add [guardrails](/openai-agents-js/guides/guardrails) to validate tool inputs or outputs.
- Dive into the TypeDoc reference for [`tool()`](/openai-agents-js/openai/agents/functions/tool) and the various hosted tool types.
